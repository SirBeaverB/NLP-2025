# 问答系统构建-实验报告
本项目旨在构建一个基于 RAG（Retrieval-Augmented Generation）架构的问答系统。该系统可以回答用户提出的任意问题，并基于指定语料库（人民日报）中的内容进行检索和生成。
完整代码见`https://github.com/SirBeaverB/NLP-2025`。


## 爬虫
《人民日报》的文章库url结构非常清晰，为`f"https://paper.people.com.cn/rmrb/html/{date_str1}/nw.D110000renmrb_{date_str2}_{idx}-{ban:02d}.htm"`

- {date_str1}：日期目录，格式如 2024-06/01

- {date_str2}：日期编号，格式如 20240601

- {idx}：文章序号（如1、2、3等）

- {ban}：版面编号（如01、02、03等）

通过遍历日期、序号和版面编号，可以自动生成所有可能的文章URL。

用 `BeautifulSoup` 解析 HTML，提取新闻正文、标题、日期、URL等元信息。

语料以JSON格式存储，用以后续处理，内容包含：

- title：文章标题

- date：发布日期

- url：原始网页链接

- content：正文内容


## 问答系统

问答系统采用rag的基本思路，主要由三部分构成：embedding检索、关键词检索、知识图谱检索。

### 1. embedding检索
 对每篇文章内容进行分块（chunking），每个chunk长度为400字，重叠200字，。
每个chunk保留原文的标题、URL、日期、全文等元信息，便于后续检索和答案溯源。预处理后数据存储于data_chunked/目录。

采用中文embedding模型`moka-ai/m3e-base`（该模型在中文语义检索任务上表现优异，兼容sentence-transformers接口，推理速度快，显存占用低），对每个chunk进行embedding。
embedding内容为“标题+正文chunk”拼接，以提升标题召回率。
embedding向量使用L2 norm归一化。


使用FAISS库构建高效的向量索引，索引类型为IndexFlatL2。
用户问题经同样的embedding模型编码后，与所有chunk的embedding做相似度检索，返回top-k最相关的chunk作为候选上下文。

### 2. 关键词检索
用户输入问题后，先用`GPT-4o-mini`提取问题关键词，并判断问题类型（事实类/开放类）。（在测试中并未使用判断问题类型这一功能。）
使用该模型的原因是，关键词提取是一个较为重要的任务，需要使用较好的LLM模型以实现效果。

对每个chunk的正文（chunk_content）进行联合关键词匹配。即只要关键词出现在chunk的正文中，该chunk就会被召回为候选结果。
对于每个chunk，统计所有关键词在标题和正文中出现的总次数，作为该chunk的召回分数。分数越高，说明与用户问题的相关性越强。
所有chunk按召回分数从高到低排序，选取top-k作为关键词检索的候选结果。

首先从用户问题中提取一个关键词，如果首次检索未能召回足够相关内容，系统会自动扩展提取关键词的数量，进行多轮检索。

### 3. 知识图谱检索
- 三元组提取

    采用`Babelscape/mrebel-large`预训练模型（一个专门用于多语言关系抽取（Relation Extraction）的Seq2Seq模型，支持中文）。

    遍历 `data/` 目录下所有 JSON 语料文件。
对每个文件，逐条读取新闻内容（content）。
对每一条文本，调用 `mREBEL` 模型，抽取出若干（主语-谓语-宾语）三元组。

    对所有三元组去重，避免重复。
每累计到 1000 条三元组，批量写入一个 CSV 文件，便于后续知识图谱构建和检索。

    提取的三元组示例：
```
中国航天科技集团有限公司,different from,中国航天科工集团有限公司
中国航天科工集团有限公司,different from,中国航天科技集团有限公司
海淀区,located in the administrative territorial entity,北京市
西北旺镇,located in the administrative territorial entity,海淀区
全国公安交管部门,applies to jurisdiction,全国
```

（曾尝试使用`ltp`自行构建三元组，用litie 的 `gplinker`模型提取三元组，效果不好，遂放弃。）

- 知识图谱构建

代码会遍历 `kg/triples/` 目录下所有 .csv 文件，逐行读取三元组。以实体（head）为key，存储该实体相关的所有三元组为字典，例：

```
{
    "中国航天科技集团有限公司": [("中国航天科技集团有限公司", "different from", "中国航天科工集团有限公司")],
    "中国": [("中国", "举办", "亚洲运动会")]
}
```

- 知识图谱检索

系统已经用`GPT-4o-mini`提取了用户问题中的关键词，这些关键词被用作实体名，优先在知识图谱中查找相关实体。
检索到的三元组会被拼接为结构化文本，作为知识图谱检索的直接答案。


根据实验，该KG其实用处不大。

### 4. 流程
分别进行以上三种检索后，embedding检索和关键词检索的结果合并去重，保证相关性和多样性。
对每个检索到的chunk，自动扩展其前后chunk内容，合并为更完整的上下文。

对于检索到的url，系统再次读取对应文章内容，构建更精准的上下文，送入大模型生成“reread答案”。

将检索到的上下文、知识图谱答案等信息被拼接成prompt，送入`Qwen2.5-7B-Instruct`进行综合推理和生成。
系统融合KG答案和RAG答案，输出最终答案。

如果首次检索未能得到答案，系统会自动扩展关键词（如用LLM生成同义词、相关词），进行第二轮检索。

### 5. 反思

出于模型、算力、时间、金钱等等限制，知识图谱构建过于简单，实际用处十分有限。`mrebel`模型能识别的三元组类型有些过于简单，主要集中在常见的主谓宾关系。对于复杂事件、隐含关系、长距离依赖等情况，模型往往无法正确抽取，导致知识图谱中缺失大量有价值的信息，进而导致基于该模型构建的知识图谱较为不完整。在实际测试过程中，虽然知识图谱检索对部分关系简单常见的事实类问题有一定帮助，但对于结构较为复杂的事实类问题，系统仍然依赖于 embedding 检索和关键词检索。许多人类认为简单的问题，由于知识图谱覆盖不到，系统依然无法给出准确答案。

还可以采取其他更多方法提高检索准确率，如传统BM25、TF-IDF等文本检索算法，与embedding检索结果融合，兼顾语义相关性和字面匹配，提升对专有名词、数字等问题的召回能力。

可以优化prompt设计，加入高质量的问答示例。
